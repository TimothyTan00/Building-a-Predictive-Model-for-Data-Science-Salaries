# -*- coding: utf-8 -*-
"""ModelTraining.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JS5yRYQxgILCnElvjsNGiluagNLfLLJd
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns

df = pd.read_csv('/content/drive/MyDrive/DSCI 550/DSCI 550 Project/Dataset/cleaned_salaries_nov24.csv')

df.head()

"""### encoding ordinal categorical variables"""

df['work_year'] = pd.Categorical(df['work_year'])

experience_order = ['EN','MI','SE','EX']
df['experience_level'] = pd.Categorical(df['experience_level'], categories=experience_order, ordered=True)

size_order = ['S', 'M', 'L']
df['company_size'] = pd.Categorical(df['company_size'], categories=size_order, ordered=True)

employment_type_order = ['FT','PT','CT','FL']
df['employment_type'] = pd.Categorical(df['employment_type'], categories=employment_type_order, ordered=True)

location_order = ['US', 'CA', 'GB', 'DE', 'ES', 'AU', 'FR', 'IN', 'NL', 'Other']
df['employee_residence'] = pd.Categorical(df['employee_residence'], categories=location_order, ordered=True)
df['company_location'] = pd.Categorical(df['company_location'], categories=location_order, ordered=True)

"""### EDA"""

diff = len(df[df['company_location'] != df['employee_residence']])/len(df)*100.0
print(f'Rows where company location and employee residence are different: {diff:.2f}%') # possible collinearity

employ = len(df[df['employment_type'] != 'FT'])/len(df)*100.0
print(f'Rows of not full time: {employ:.2f}%')

df.info()

"""## Feature EDA"""

X_cat = ['work_year','experience_level', 'employment_type', 'job_title_cleaned','employee_residence', 'remote_ratio', 'company_location','company_size']

# Univariate Analysis: Bar plots for categorical variables
for col in X_cat:
    plt.figure(figsize=(10, 6))
    if col == 'job_title_cleaned':
      sns.countplot(y=df[col], orient='h')
    else:
      sns.countplot(x=df[col])
    plt.title(f'Frequency of {col}', fontsize=14)
    plt.xlabel(col)
    plt.ylabel('Count')
    plt.xticks(rotation=0)
    plt.show()

# Bivariate Analysis: Box plots for categorical predictors vs salary_in_usd
for col in X_cat:
    plt.figure(figsize=(10, 6))
    sns.boxplot(x=df[col], y=df['salary_in_usd']) #, order=df[col].value_counts().index)
    plt.title(f'{col} vs Salary in USD', fontsize=14)
    plt.xlabel(col)
    plt.ylabel('Salary in USD')
    if col == 'job_title_cleaned':
      plt.xticks(rotation=90)
    else:
      plt.xticks(rotation=0)
    plt.show()

"""## Collinearity"""

import numpy as np
from scipy.stats import chi2_contingency

def cramers_v(x, y):
    contingency_table = pd.crosstab(x, y)
    chi2 = chi2_contingency(contingency_table)[0]
    n = contingency_table.sum().sum()
    phi2 = chi2 / n
    r, k = contingency_table.shape
    return np.sqrt(phi2 / min((k - 1), (r - 1)))

# Create a correlation matrix for categorical variables
cat_cols = X_cat
cramers_v_matrix = pd.DataFrame(np.zeros((len(cat_cols), len(cat_cols))),
                                index=cat_cols,
                                columns=cat_cols)

for col1 in cat_cols:
    for col2 in cat_cols:
        if col1 != col2:
            cramers_v_matrix.loc[col1, col2] = cramers_v(df[col1], df[col2])

display(cramers_v_matrix)

plt.figure(figsize=(10, 8))
sns.heatmap(cramers_v_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('CramÃ©r\'s V Correlation Heatmap')
plt.show()

X_cat.remove('company_location')

"""`employee_residence` and `company_location` are redundant information. The analysis will continue with `employee_residence`."""

print(X_cat)

"""## Feature Importance Analysis & Model Selection"""

result = dict()

"""### Encoding into Numerical Variables"""

y_col = 'salary_in_usd'

X_cat = ['work_year', 'experience_level', 'employment_type', 'job_title_cleaned','employee_residence', 'remote_ratio', 'company_size']
X = df[X_cat]
X.columns

y = df[y_col]

cat_col = ['job_title_cleaned','employee_residence']
X_dummy = pd.get_dummies(X, columns=cat_col, drop_first=False)

X_dummy['work_year'] = pd.Categorical(df['work_year'], categories=[2020, 2021, 2022, 2023, 2024], ordered=True).codes
X_dummy['experience_level'] = pd.Categorical(df['experience_level'], categories=experience_order, ordered=True).codes
X_dummy['company_size'] = pd.Categorical(df['company_size'], categories=size_order, ordered=True).codes
X_dummy['employment_type'] = pd.Categorical(df['employment_type'], categories=employment_type_order, ordered=True).codes

X_dummy.columns

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import mean_squared_error, r2_score

X_train, X_test, y_train, y_test = train_test_split(X_dummy, y, random_state=42)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

scaler_y = StandardScaler()
y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1)).flatten()
y_test_scaled = scaler_y.transform(y_test.values.reshape(-1, 1)).flatten()

"""## Model Training and Selection:

## Linear Models (Multiple Linear Regression & Lasso):
"""

from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor

print("Linear Regression")

mlr = LinearRegression()

mlr.fit(X_train, y_train)

y_pred = mlr.predict(X_test)


mlr_mse = mean_squared_error(y_test, y_pred)
mlr_r2 = r2_score(y_test, y_pred)
print(f"Mean Squared Error: {mlr_mse:.2f}")
print(f"R^2 Score: {mlr_r2:.2f}")

coefficients = mlr.coef_
features = X_train.columns

coeff_df = pd.DataFrame({'Feature': features, 'Coefficient': coefficients})
coeff_df.sort_values(by='Coefficient', ascending=False, inplace=True)

display(coeff_df)

result['Multiple Linear Regression'] = mlr_mse, mlr_r2

import matplotlib.pyplot as plt

plt.scatter(y_test, y_pred, alpha=0.5)
plt.xlabel('Actual Salaries')
plt.ylabel('Predicted Salaries')
plt.title('Actual vs Predicted Salaries')
plt.show()

"""### Lasso Regression"""

from sklearn.linear_model import Lasso
from sklearn.model_selection import GridSearchCV

print("Lasso Regression")

# Define a range of alpha values to test
param_grid = {'alpha': [0.01, 0.1, 0.5, 1, 5, 10]}
lasso_cv = GridSearchCV(Lasso(max_iter=10000), param_grid, cv=5, scoring='neg_mean_squared_error')
lasso_cv.fit(X_train_scaled, y_train)

# Best alpha
best_alpha = lasso_cv.best_params_['alpha']
print(f"Best alpha: {best_alpha}")

# Re-train Lasso with the optimal alpha
lasso = Lasso(alpha=best_alpha)
lasso.fit(X_train_scaled, y_train)

y_pred = lasso.predict(X_test_scaled)


lasso_mse = mean_squared_error(y_test, y_pred)
lasso_r2 = r2_score(y_test, y_pred)
print(f"Mean Squared Error: {lasso_mse:.2f}")
print(f"R^2 Score: {lasso_r2:.2f}")

coefficients = lasso.coef_
features = X_train.columns

coeff_df = pd.DataFrame({'Feature': features, 'Coefficient': coefficients})
coeff_df.sort_values(by='Coefficient', ascending=False, inplace=True)

display(coeff_df)

result['Lasso Regression'] = lasso_mse, lasso_r2

plt.scatter(y_test, y_pred, alpha=0.5)
plt.xlabel('Actual Salaries')
plt.ylabel('Predicted Salaries')
plt.title('Actual vs Predicted Salaries')
plt.show()

result

"""Lasso Regression (effectively a feature selection tool) barely improved the R^2 mean squared error from Multiple Linear Regression."""

plt.barh(coeff_df['Feature'], coeff_df['Coefficient'])
plt.xlabel('Coefficient Value')
plt.ylabel('Features')
plt.title('Feature Importance (Lasso Regression)')
plt.show()

"""## Shifting to Tree based Model
### Using RandomForest:
"""

from sklearn.ensemble import RandomForestRegressor

rf = RandomForestRegressor(random_state = 42)
rf.fit(X_train, y_train)
# importance = pd.Series(rf.feature_importances_, index=X_train.columns)
# display(importance)

y_pred = rf.predict(X_test)

rf_mse = mean_squared_error(y_test, y_pred)
rf_r2 = r2_score(y_test, y_pred)
print(f"Mean Squared Error: {rf_mse:.2f}")
print(f"R^2 Score: {rf_r2:.2f}")

result['Random Forest'] = rf_mse, rf_r2

plt.scatter(y_test, y_pred, alpha=0.5)
plt.xlabel('Actual Salaries')
plt.ylabel('Predicted Salaries')
plt.title('Actual vs Predicted Salaries')
plt.show()

result

importance = pd.Series(rf.feature_importances_, index=X_train.columns)
# importance.sort_values(ascending=False).plot(kind='bar')
rf_selected = importance[importance >0.01].sort_values(ascending=False).reset_index()
rf_selected

X_train_rf = X_train[rf_selected]
X_test_rf = X_test[rf_selected]

# Step 4: Train a new model using only the important features
new_model = RandomForestRegressor(random_state=42)
new_model.fit(X_train_rf, y_train)

# Step 5: Evaluate the new model on the test set
y_pred = new_model.predict(X_test_rf)
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error: {mse:.2f}")
print(f"R^2 Score: {r2:.2f}")

"""Feature selection for random forest made model worse.

### Using XGBoost
"""

import xgboost as xgb
from sklearn.model_selection import GridSearchCV

print("XGBoost")

param_grid = {
    'n_estimators': [50, 100, 200],
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 6, 9],
    'subsample': [0.8, 1.0],
    'colsample_bytree': [0.8, 1.0]
}

xgb_model = xgb.XGBRegressor(objective='reg:squarederror', random_state=42)
grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', verbose=1)
grid_search.fit(X_train, y_train)

# Best parameters
print(f"Best parameters: {grid_search.best_params_}")

grid_search.best_params_

best_xgb_model = grid_search.best_estimator_

y_pred = best_xgb_model.predict(X_test)

xgb_mse = mean_squared_error(y_test, y_pred)
xgb_r2 = r2_score(y_test, y_pred)
print(f"Mean Squared Error: {xgb_mse:.2f}")
print(f"R^2 Score: {xgb_r2:.2f}")

plt.scatter(y_test, y_pred, alpha=0.5)
plt.xlabel('Actual Salaries')
plt.ylabel('Predicted Salaries')
plt.title('XGBoost: Actual vs Predicted Salaries')
plt.show()

result['XGBoost'] = xgb_mse, xgb_r2

xgb.plot_importance(best_xgb_model, importance_type='weight', max_num_features=10)
plt.title('Top 10 Feature Importances')
plt.show()

result

"""## Support Vector Regression:"""

from sklearn.svm import SVR

# Initialize the SVR model with an RBF kernel
svr_model = SVR(kernel='rbf', C=1.0, epsilon=0.1)  # Adjust 'C' and 'epsilon' for tuning

# Train the model
svr_model.fit(X_train_scaled, y_train_scaled)

# Make predictions
y_pred_scaled = svr_model.predict(X_test_scaled)

# Inverse transform the predictions and true values back to the original scale
y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()
y_test_original = scaler_y.inverse_transform(y_test_scaled.reshape(-1, 1)).flatten()

# Evaluate the model
svr_r2 = r2_score(y_test_original, y_pred)
svr_mse = mean_squared_error(y_test_original, y_pred)

print(f"R^2: {svr_r2}")
print(f"MSE: {svr_mse}")

# param_grid = {
#     'C': [0.1, 1, 10, 100],
#     'epsilon': [0.01, 0.1, 0.5],
#     'kernel': ['rbf', 'linear']
# }

# grid_search = GridSearchCV(SVR(), param_grid, cv=5, scoring='neg_mean_squared_error', verbose=1)
# grid_search.fit(X_train_scaled, y_train_scaled)

# # Best parameters
# print(f"Best parameters: {grid_search.best_params_}")

# # Train SVR with the best parameters
# best_svr = grid_search.best_estimator_

# # Make predictions and evaluate
# y_pred_scaled = best_svr.predict(X_test_scaled)
# y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).flatten()

# op_svr_r2 = r2_score(y_test_original, y_pred)
# op_svr_mse = mean_squared_error(y_test_original, y_pred)
# rmse = np.sqrt(mean_squared_error(y_test_original, y_pred))

# print(f"Optimized R^2: {op_svr_r2}")
# print(f"Optimized MSE: {op_svr_mse}")

result['SVR'] = svr_mse, svr_r2

"""## KNN:"""

from sklearn.neighbors import KNeighborsRegressor

param_grid = {
    'n_neighbors': [5, 7, 10],
    'weights': ['uniform', 'distance']
}

grid_search = GridSearchCV(KNeighborsRegressor(), param_grid, cv=5, scoring='neg_mean_squared_error', verbose=1)
grid_search.fit(X_train_scaled, y_train)

# Best parameters
print(f"Best parameters: {grid_search.best_params_}")

# Train KNN with the best parameters
best_knn_model = grid_search.best_estimator_

# Make predictions and evaluate
y_pred = best_knn_model.predict(X_test_scaled)

knn_r2 = r2_score(y_test, y_pred)
knn_mse = mean_squared_error(y_test, y_pred)

print(f"Optimized R^2: {knn_r2}")
print(f"Optimized MSE: {knn_mse}")

result['KNN'] = knn_mse, knn_r2

"""# Results"""

result_df = pd.DataFrame.from_dict(result, orient='index', columns=['MSE', 'R^2'])
result_df['RSME'] = np.sqrt(result_df['MSE'])


display(result_df.sort_values(by='RSME', ascending=True))

"""Tree-based model, especially XGBoost performed the best."""

